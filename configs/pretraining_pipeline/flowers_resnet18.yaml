optimizer:
  _target_: torch.optim.SGD
  lr: 0.1
  momentum: 0.9
  weight_decay: 0
dataset:
  train:
    _target_: torchvision.datasets.Flowers102
    split: train
    transform:
      _target_: torchvision.transforms.Compose
      _recursive_: true
      transforms:
        - _target_: torchvision.transforms.RandomCrop
          size: 224
          padding: 24
        - _target_: torchvision.transforms.RandomHorizontalFlip
        - _target_: torchvision.transforms.ToTensor
    root: ${core.dataset_root}/flowers102
    download: Yes
  test:
    _target_: torchvision.datasets.Flowers102
    split: val
    transform:
      _target_: torchvision.transforms.Compose
      _recursive_: true
      transforms:
        - _target_: torchvision.transforms.ToTensor
        - _target_: torchvision.transforms.Resize
          size: [224, 224]
    root: ${core.dataset_root}/flowers102
    download: No
dataloader:
  _target_: torch.utils.data.DataLoader
  batch_size: 16
  shuffle: true
  sampler: null
  num_workers: 0
  collate_fn: null
  pin_memory: null
  drop_last: no
schema:
  epochs: 100
early_stopping:
  _target_: base.utils.EarlyStopper
  patience: 10
  min_delta: 0
scheduler:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  T_max: ${pretraining_pipeline.schema.epochs}